{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MAST30034 Applied Data Science week 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Today\n",
    "\n",
    "0.  Environment\n",
    "1. Install Pyspark\n",
    "2. Pyspark初体验\n",
    "3. Download Dataset\n",
    "4. Pyspark basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 0. Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Installing Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For WSL2 users:**\n",
    "\n",
    "1. update ubuntu\n",
    "    - `sudo apt update`\n",
    "2. Check Java\n",
    "    - `java --version`\n",
    "3. Install Java\n",
    "    - `sudo apt install openjdk-8-jdk`\n",
    "4. Check Java\n",
    "    - `java --version`\n",
    "5. Path\n",
    "    - `echo 'JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"' | sudo tee -a /etc/environment`\n",
    "6. Apply\n",
    "    - `source /etc/environment`\n",
    "7. Python install\n",
    "    - `pip3 install pyspark pyarrow pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MacOS users:**\n",
    "\n",
    "Follow tutorial sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Pyspark 初体验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark\n",
    "\n",
    "PySpark v.s. Pandas:\n",
    "- 1. 速度更快\n",
    "- 2. 内存更大\n",
    "- 3. 并行的，集成的运算引擎\n",
    "\n",
    "PySpark supports all of Spark’s features such as Spark SQL, DataFrames, Structured Streaming, Machine Learning (MLlib) and Spark Core. Using PySpark we can run applications parallelly on the distributed cluster (multiple nodes).\n",
    "\n",
    "PySpark is very well used in Data Science and Machine Learning community as there are many widely used data science libraries written in Python including NumPy, TensorFlow. Also used due to its efficient processing of large datasets. PySpark has been used by many organizations like Walmart, Trivago, Sanofi, Runtastic, and many more.\n",
    "\n",
    "#### Advantages\n",
    "- fast speed\n",
    "- large memory\n",
    "- combine local and distributed data transformation\n",
    "- lazy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/02 14:47:49 WARN Utils: Your hostname, Luo resolves to a loopback address: 127.0.1.1; using 172.17.36.219 instead (on interface eth0)\n",
      "23/08/02 14:47:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/02 14:47:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Start a Spark session, all analysis are then based on the session\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"CPU ADS wk 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    # 如果后续发现数据太大内存不够，改这里\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.executer.memory\", \"8g\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark.app.name =  CPU ADS wk 1\n"
     ]
    }
   ],
   "source": [
    "conf = spark.sparkContext.getConf()\n",
    "print(\"spark.app.name = \", conf.get(\"spark.app.name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An important property of Spark is that it is immutable**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "做整个项目之前我们首先要安排好我们这个project的文件夹的结构，\n",
    "\n",
    "例如我们的data要全部归纳在project/data/里， code归纳在project/notebooks/里。然后再细分为raw data和curated data等等\n",
    "\n",
    "所以第一步我们可以先手动创建一个notebook文件夹然后在里面创建我们第一个notebook用来下载数据\n",
    "\n",
    "然后我们来创建data文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_relative_dir = f'../data/'\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "\n",
    "for type in ['raw', 'curate']:\n",
    "    #path ../data/raw or ../data/curated\n",
    "    path = output_relative_dir + type\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    for source in ['external', 'tlc_data']:\n",
    "        #path ../data/raw/external or ../data/raw/tlc_data\n",
    "        path = output_relative_dir + type + '/' + source\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建图像文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in ['2019', '2021']:\n",
    "    path = f'../data/raw/tlc_data/'\n",
    "    if not os.path.exists(path + year):\n",
    "        os.makedirs(path + year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那我们处理data可能分批次处理并做preliminary，那在curated里我们要给data清理做个分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_relative_dir = f'../data/curate/tlc_data/'\n",
    "#path ../data/curate/tlc_data/first_clean or ../data/curate/tlc_data/final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那我们的文件夹结构已经初步规划好了，接下来就可以把原始数据下载下来了，我们要下载到的路径是：\n",
    "\n",
    "`project/data/raw/tlc_data/2019` and `project/data/raw/tlc_data/2021`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步先找到完整的下载地址： `https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{YEAR}-{MONTH}.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_TEMPLATE = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设定好下载路径的template，以及我们需要的年月的范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = ['2019', '2021']\n",
    "\n",
    "MONTH = range(1, 13)\n",
    "\n",
    "output_relative_dir = f'../data/raw/tlc_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用两个for loop去下载两年中每个月的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 2019 1\n",
      "finished 2019 01\n",
      "starting 2019 2\n",
      "finished 2019 02\n",
      "starting 2019 3\n",
      "finished 2019 03\n",
      "starting 2019 4\n",
      "finished 2019 04\n",
      "starting 2019 5\n",
      "finished 2019 05\n",
      "starting 2019 6\n",
      "finished 2019 06\n",
      "starting 2019 7\n",
      "finished 2019 07\n",
      "starting 2019 8\n",
      "finished 2019 08\n",
      "starting 2019 9\n",
      "finished 2019 09\n",
      "starting 2019 10\n",
      "finished 2019 10\n",
      "starting 2019 11\n",
      "finished 2019 11\n",
      "starting 2019 12\n",
      "finished 2019 12\n",
      "starting 2021 1\n",
      "finished 2021 01\n",
      "starting 2021 2\n",
      "finished 2021 02\n",
      "starting 2021 3\n",
      "finished 2021 03\n",
      "starting 2021 4\n",
      "finished 2021 04\n",
      "starting 2021 5\n",
      "finished 2021 05\n",
      "starting 2021 6\n",
      "finished 2021 06\n",
      "starting 2021 7\n",
      "finished 2021 07\n",
      "starting 2021 8\n",
      "finished 2021 08\n",
      "starting 2021 9\n",
      "finished 2021 09\n",
      "starting 2021 10\n",
      "finished 2021 10\n",
      "starting 2021 11\n",
      "finished 2021 11\n",
      "starting 2021 12\n",
      "finished 2021 12\n"
     ]
    }
   ],
   "source": [
    "for year in YEAR:\n",
    "    for month in MONTH:\n",
    "        print(f'starting {year} {month}')\n",
    "        month = str(month).zfill(2)\n",
    "        #url = https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-03.parquet\n",
    "        url = f'{URL_TEMPLATE}{year}-{month}.parquet'\n",
    "        output_dir = f'{output_relative_dir}/{year}/{year}-{month}.parquet'\n",
    "        urlretrieve(url, output_dir)\n",
    "        print(f'finished {year} {month}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Pyspark Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A new data format: Parquet\n",
    "\n",
    "- stored in columns\n",
    "- single data type per column\n",
    "- compressed much more\n",
    "- faster to read and run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:46:40</td><td>2019-01-01 00:53:20</td><td>1.0</td><td>1.5</td><td>1.0</td><td>N</td><td>151</td><td>239</td><td>1</td><td>7.0</td><td>0.5</td><td>0.5</td><td>1.65</td><td>0.0</td><td>0.3</td><td>9.95</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:59:47</td><td>2019-01-01 01:18:59</td><td>1.0</td><td>2.6</td><td>1.0</td><td>N</td><td>239</td><td>246</td><td>1</td><td>14.0</td><td>0.5</td><td>0.5</td><td>1.0</td><td>0.0</td><td>0.3</td><td>16.3</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2018-12-21 13:48:30</td><td>2018-12-21 13:52:40</td><td>3.0</td><td>0.0</td><td>1.0</td><td>N</td><td>236</td><td>236</td><td>1</td><td>4.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>5.8</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2018-11-28 15:52:25</td><td>2018-11-28 15:55:45</td><td>5.0</td><td>0.0</td><td>1.0</td><td>N</td><td>193</td><td>193</td><td>2</td><td>3.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>7.55</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2018-11-28 15:56:57</td><td>2018-11-28 15:58:33</td><td>5.0</td><td>0.0</td><td>2.0</td><td>N</td><td>193</td><td>193</td><td>2</td><td>52.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>55.55</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2018-11-28 16:25:49</td><td>2018-11-28 16:28:26</td><td>5.0</td><td>0.0</td><td>1.0</td><td>N</td><td>193</td><td>193</td><td>2</td><td>3.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>5.76</td><td>0.3</td><td>13.31</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2018-11-28 16:29:37</td><td>2018-11-28 16:33:43</td><td>5.0</td><td>0.0</td><td>2.0</td><td>N</td><td>193</td><td>193</td><td>2</td><td>52.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>55.55</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:21:28</td><td>2019-01-01 00:28:37</td><td>1.0</td><td>1.3</td><td>1.0</td><td>N</td><td>163</td><td>229</td><td>1</td><td>6.5</td><td>0.5</td><td>0.5</td><td>1.25</td><td>0.0</td><td>0.3</td><td>9.05</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:32:01</td><td>2019-01-01 00:45:39</td><td>1.0</td><td>3.7</td><td>1.0</td><td>N</td><td>229</td><td>7</td><td>1</td><td>13.5</td><td>0.5</td><td>0.5</td><td>3.7</td><td>0.0</td><td>0.3</td><td>18.5</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:57:32</td><td>2019-01-01 01:09:32</td><td>2.0</td><td>2.1</td><td>1.0</td><td>N</td><td>141</td><td>234</td><td>1</td><td>10.0</td><td>0.5</td><td>0.5</td><td>1.7</td><td>0.0</td><td>0.3</td><td>13.0</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:24:04</td><td>2019-01-01 00:47:06</td><td>2.0</td><td>2.8</td><td>1.0</td><td>N</td><td>246</td><td>162</td><td>1</td><td>15.0</td><td>0.5</td><td>0.5</td><td>3.25</td><td>0.0</td><td>0.3</td><td>19.55</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:21:59</td><td>2019-01-01 00:28:24</td><td>1.0</td><td>0.7</td><td>1.0</td><td>N</td><td>238</td><td>151</td><td>1</td><td>5.5</td><td>0.5</td><td>0.5</td><td>1.7</td><td>0.0</td><td>0.3</td><td>8.5</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:45:21</td><td>2019-01-01 01:31:05</td><td>1.0</td><td>8.7</td><td>1.0</td><td>N</td><td>163</td><td>25</td><td>1</td><td>34.5</td><td>0.5</td><td>0.5</td><td>7.15</td><td>0.0</td><td>0.3</td><td>42.95</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:43:19</td><td>2019-01-01 01:07:42</td><td>1.0</td><td>6.3</td><td>1.0</td><td>N</td><td>224</td><td>25</td><td>1</td><td>21.5</td><td>0.5</td><td>0.5</td><td>5.7</td><td>0.0</td><td>0.3</td><td>28.5</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:58:24</td><td>2019-01-01 01:15:18</td><td>1.0</td><td>2.7</td><td>1.0</td><td>N</td><td>141</td><td>234</td><td>1</td><td>13.0</td><td>0.5</td><td>0.5</td><td>1.0</td><td>0.0</td><td>0.3</td><td>15.3</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2019-01-01 00:23:14</td><td>2019-01-01 00:25:40</td><td>1.0</td><td>0.38</td><td>1.0</td><td>N</td><td>170</td><td>170</td><td>2</td><td>3.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>4.8</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2019-01-01 00:39:51</td><td>2019-01-01 00:48:02</td><td>1.0</td><td>0.55</td><td>1.0</td><td>N</td><td>170</td><td>170</td><td>1</td><td>6.5</td><td>0.5</td><td>0.5</td><td>1.95</td><td>0.0</td><td>0.3</td><td>9.75</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2019-01-01 00:46:00</td><td>2019-01-01 00:49:07</td><td>1.0</td><td>0.3</td><td>1.0</td><td>N</td><td>107</td><td>107</td><td>1</td><td>4.0</td><td>0.5</td><td>0.5</td><td>1.06</td><td>0.0</td><td>0.3</td><td>6.36</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2019-01-01 00:57:45</td><td>2019-01-01 01:03:51</td><td>1.0</td><td>1.42</td><td>1.0</td><td>N</td><td>170</td><td>141</td><td>1</td><td>6.5</td><td>0.5</td><td>0.5</td><td>1.56</td><td>0.0</td><td>0.3</td><td>9.36</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2019-01-01 00:16:16</td><td>2019-01-01 00:25:57</td><td>1.0</td><td>1.72</td><td>1.0</td><td>N</td><td>41</td><td>247</td><td>2</td><td>9.0</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>10.3</td><td>null</td><td>null</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|       1| 2019-01-01 00:46:40|  2019-01-01 00:53:20|            1.0|          1.5|       1.0|                 N|         151|         239|           1|        7.0|  0.5|    0.5|      1.65|         0.0|                  0.3|        9.95|                null|       null|\n",
       "|       1| 2019-01-01 00:59:47|  2019-01-01 01:18:59|            1.0|          2.6|       1.0|                 N|         239|         246|           1|       14.0|  0.5|    0.5|       1.0|         0.0|                  0.3|        16.3|                null|       null|\n",
       "|       2| 2018-12-21 13:48:30|  2018-12-21 13:52:40|            3.0|          0.0|       1.0|                 N|         236|         236|           1|        4.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         5.8|                null|       null|\n",
       "|       2| 2018-11-28 15:52:25|  2018-11-28 15:55:45|            5.0|          0.0|       1.0|                 N|         193|         193|           2|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        7.55|                null|       null|\n",
       "|       2| 2018-11-28 15:56:57|  2018-11-28 15:58:33|            5.0|          0.0|       2.0|                 N|         193|         193|           2|       52.0|  0.0|    0.5|       0.0|         0.0|                  0.3|       55.55|                null|       null|\n",
       "|       2| 2018-11-28 16:25:49|  2018-11-28 16:28:26|            5.0|          0.0|       1.0|                 N|         193|         193|           2|        3.5|  0.5|    0.5|       0.0|        5.76|                  0.3|       13.31|                null|       null|\n",
       "|       2| 2018-11-28 16:29:37|  2018-11-28 16:33:43|            5.0|          0.0|       2.0|                 N|         193|         193|           2|       52.0|  0.0|    0.5|       0.0|         0.0|                  0.3|       55.55|                null|       null|\n",
       "|       1| 2019-01-01 00:21:28|  2019-01-01 00:28:37|            1.0|          1.3|       1.0|                 N|         163|         229|           1|        6.5|  0.5|    0.5|      1.25|         0.0|                  0.3|        9.05|                null|       null|\n",
       "|       1| 2019-01-01 00:32:01|  2019-01-01 00:45:39|            1.0|          3.7|       1.0|                 N|         229|           7|           1|       13.5|  0.5|    0.5|       3.7|         0.0|                  0.3|        18.5|                null|       null|\n",
       "|       1| 2019-01-01 00:57:32|  2019-01-01 01:09:32|            2.0|          2.1|       1.0|                 N|         141|         234|           1|       10.0|  0.5|    0.5|       1.7|         0.0|                  0.3|        13.0|                null|       null|\n",
       "|       1| 2019-01-01 00:24:04|  2019-01-01 00:47:06|            2.0|          2.8|       1.0|                 N|         246|         162|           1|       15.0|  0.5|    0.5|      3.25|         0.0|                  0.3|       19.55|                null|       null|\n",
       "|       1| 2019-01-01 00:21:59|  2019-01-01 00:28:24|            1.0|          0.7|       1.0|                 N|         238|         151|           1|        5.5|  0.5|    0.5|       1.7|         0.0|                  0.3|         8.5|                null|       null|\n",
       "|       1| 2019-01-01 00:45:21|  2019-01-01 01:31:05|            1.0|          8.7|       1.0|                 N|         163|          25|           1|       34.5|  0.5|    0.5|      7.15|         0.0|                  0.3|       42.95|                null|       null|\n",
       "|       1| 2019-01-01 00:43:19|  2019-01-01 01:07:42|            1.0|          6.3|       1.0|                 N|         224|          25|           1|       21.5|  0.5|    0.5|       5.7|         0.0|                  0.3|        28.5|                null|       null|\n",
       "|       1| 2019-01-01 00:58:24|  2019-01-01 01:15:18|            1.0|          2.7|       1.0|                 N|         141|         234|           1|       13.0|  0.5|    0.5|       1.0|         0.0|                  0.3|        15.3|                null|       null|\n",
       "|       2| 2019-01-01 00:23:14|  2019-01-01 00:25:40|            1.0|         0.38|       1.0|                 N|         170|         170|           2|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.8|                null|       null|\n",
       "|       2| 2019-01-01 00:39:51|  2019-01-01 00:48:02|            1.0|         0.55|       1.0|                 N|         170|         170|           1|        6.5|  0.5|    0.5|      1.95|         0.0|                  0.3|        9.75|                null|       null|\n",
       "|       2| 2019-01-01 00:46:00|  2019-01-01 00:49:07|            1.0|          0.3|       1.0|                 N|         107|         107|           1|        4.0|  0.5|    0.5|      1.06|         0.0|                  0.3|        6.36|                null|       null|\n",
       "|       2| 2019-01-01 00:57:45|  2019-01-01 01:03:51|            1.0|         1.42|       1.0|                 N|         170|         141|           1|        6.5|  0.5|    0.5|      1.56|         0.0|                  0.3|        9.36|                null|       null|\n",
       "|       2| 2019-01-01 00:16:16|  2019-01-01 00:25:57|            1.0|         1.72|       1.0|                 N|          41|         247|           2|        9.0|  0.5|    0.5|       0.0|         0.0|                  0.3|        10.3|                null|       null|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:================>                                        (5 + 12) / 17]\r"
     ]
    }
   ],
   "source": [
    "sdf = spark.read.parquet(path + \"2019-01.parquet\")\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7696617"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/*.parquet'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path + '*.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>VendorID</th><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>RatecodeID</th><th>store_and_fwd_flag</th><th>PULocationID</th><th>DOLocationID</th><th>payment_type</th><th>fare_amount</th><th>extra</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>improvement_surcharge</th><th>total_amount</th><th>congestion_surcharge</th><th>airport_fee</th></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:46:40</td><td>2019-01-01 00:53:20</td><td>1.0</td><td>1.5</td><td>1.0</td><td>N</td><td>151</td><td>239</td><td>1</td><td>7.0</td><td>0.5</td><td>0.5</td><td>1.65</td><td>0.0</td><td>0.3</td><td>9.95</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>1</td><td>2019-01-01 00:59:47</td><td>2019-01-01 01:18:59</td><td>1.0</td><td>2.6</td><td>1.0</td><td>N</td><td>239</td><td>246</td><td>1</td><td>14.0</td><td>0.5</td><td>0.5</td><td>1.0</td><td>0.0</td><td>0.3</td><td>16.3</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2018-12-21 13:48:30</td><td>2018-12-21 13:52:40</td><td>3.0</td><td>0.0</td><td>1.0</td><td>N</td><td>236</td><td>236</td><td>1</td><td>4.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>5.8</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2018-11-28 15:52:25</td><td>2018-11-28 15:55:45</td><td>5.0</td><td>0.0</td><td>1.0</td><td>N</td><td>193</td><td>193</td><td>2</td><td>3.5</td><td>0.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>7.55</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>2</td><td>2018-11-28 15:56:57</td><td>2018-11-28 15:58:33</td><td>5.0</td><td>0.0</td><td>2.0</td><td>N</td><td>193</td><td>193</td><td>2</td><td>52.0</td><td>0.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>0.3</td><td>55.55</td><td>null</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
       "|       1| 2019-01-01 00:46:40|  2019-01-01 00:53:20|            1.0|          1.5|       1.0|                 N|         151|         239|           1|        7.0|  0.5|    0.5|      1.65|         0.0|                  0.3|        9.95|                null|       null|\n",
       "|       1| 2019-01-01 00:59:47|  2019-01-01 01:18:59|            1.0|          2.6|       1.0|                 N|         239|         246|           1|       14.0|  0.5|    0.5|       1.0|         0.0|                  0.3|        16.3|                null|       null|\n",
       "|       2| 2018-12-21 13:48:30|  2018-12-21 13:52:40|            3.0|          0.0|       1.0|                 N|         236|         236|           1|        4.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         5.8|                null|       null|\n",
       "|       2| 2018-11-28 15:52:25|  2018-11-28 15:55:45|            5.0|          0.0|       1.0|                 N|         193|         193|           2|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        7.55|                null|       null|\n",
       "|       2| 2018-11-28 15:56:57|  2018-11-28 15:58:33|            5.0|          0.0|       2.0|                 N|         193|         193|           2|       52.0|  0.0|    0.5|       0.0|         0.0|                  0.3|       55.55|                null|       null|\n",
       "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_sdf = spark.read.parquet(path + '*.parquet')\n",
    "full_sdf.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84598444"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:46:40</td>\n",
       "      <td>2019-01-01 00:53:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>151</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:59:47</td>\n",
       "      <td>2019-01-01 01:18:59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-21 13:48:30</td>\n",
       "      <td>2018-12-21 13:52:40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-28 15:52:25</td>\n",
       "      <td>2018-11-28 15:55:45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-28 15:56:57</td>\n",
       "      <td>2018-11-28 15:58:33</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>52.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>55.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696612</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:37:20</td>\n",
       "      <td>2019-02-01 00:10:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>142</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.76</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696613</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:28:00</td>\n",
       "      <td>2019-01-31 23:50:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>48</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>48.80</td>\n",
       "      <td>5.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>54.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696614</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:11:00</td>\n",
       "      <td>2019-01-31 23:46:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>159</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>51.05</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>54.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696615</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:03:00</td>\n",
       "      <td>2019-01-31 23:14:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7696616</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-31 23:41:03</td>\n",
       "      <td>2019-02-01 00:19:16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>237</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7696617 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0               1  2019-01-01 00:46:40   2019-01-01 00:53:20              1.0   \n",
       "1               1  2019-01-01 00:59:47   2019-01-01 01:18:59              1.0   \n",
       "2               2  2018-12-21 13:48:30   2018-12-21 13:52:40              3.0   \n",
       "3               2  2018-11-28 15:52:25   2018-11-28 15:55:45              5.0   \n",
       "4               2  2018-11-28 15:56:57   2018-11-28 15:58:33              5.0   \n",
       "...           ...                  ...                   ...              ...   \n",
       "7696612         2  2019-01-31 23:37:20   2019-02-01 00:10:43              NaN   \n",
       "7696613         2  2019-01-31 23:28:00   2019-01-31 23:50:50              NaN   \n",
       "7696614         2  2019-01-31 23:11:00   2019-01-31 23:46:00              NaN   \n",
       "7696615         2  2019-01-31 23:03:00   2019-01-31 23:14:00              NaN   \n",
       "7696616         2  2019-01-31 23:41:03   2019-02-01 00:19:16              NaN   \n",
       "\n",
       "         trip_distance  RatecodeID store_and_fwd_flag  PULocationID  \\\n",
       "0                 1.50         1.0                  N           151   \n",
       "1                 2.60         1.0                  N           239   \n",
       "2                 0.00         1.0                  N           236   \n",
       "3                 0.00         1.0                  N           193   \n",
       "4                 0.00         2.0                  N           193   \n",
       "...                ...         ...                ...           ...   \n",
       "7696612          10.24         NaN               None           142   \n",
       "7696613          12.43         NaN               None            48   \n",
       "7696614           9.14         NaN               None           159   \n",
       "7696615           0.00         NaN               None           265   \n",
       "7696616          12.30         NaN               None           237   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                 239             1         7.00   0.50      0.5        1.65   \n",
       "1                 246             1        14.00   0.50      0.5        1.00   \n",
       "2                 236             1         4.50   0.50      0.5        0.00   \n",
       "3                 193             2         3.50   0.50      0.5        0.00   \n",
       "4                 193             2        52.00   0.00      0.5        0.00   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "7696612            95             0         0.00   2.75      0.0        0.00   \n",
       "7696613           213             0        48.80   5.50      0.0        0.00   \n",
       "7696614           246             0        51.05   2.75      0.5        0.00   \n",
       "7696615           265             0         0.00   0.00      0.5        9.82   \n",
       "7696616           197             0         0.00   2.75      0.0        0.00   \n",
       "\n",
       "         tolls_amount  improvement_surcharge  total_amount  \\\n",
       "0                0.00                    0.3          9.95   \n",
       "1                0.00                    0.3         16.30   \n",
       "2                0.00                    0.3          5.80   \n",
       "3                0.00                    0.3          7.55   \n",
       "4                0.00                    0.3         55.55   \n",
       "...               ...                    ...           ...   \n",
       "7696612          5.76                    0.3          0.00   \n",
       "7696613          0.00                    0.3         54.60   \n",
       "7696614          0.00                    0.3         54.60   \n",
       "7696615          0.00                    0.3          0.00   \n",
       "7696616          0.00                    0.3          0.00   \n",
       "\n",
       "         congestion_surcharge airport_fee  \n",
       "0                         NaN        None  \n",
       "1                         NaN        None  \n",
       "2                         NaN        None  \n",
       "3                         NaN        None  \n",
       "4                         NaN        None  \n",
       "...                       ...         ...  \n",
       "7696612                   NaN        None  \n",
       "7696613                   NaN        None  \n",
       "7696614                   NaN        None  \n",
       "7696615                   NaN        None  \n",
       "7696616                   NaN        None  \n",
       "\n",
       "[7696617 rows x 19 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(path + '2019-01.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = Path('../data/')\n",
    "full_df = pd.concat(\n",
    "    pd.read_parquet(parquet_file)\n",
    "    for parquet_file in data_dir.glob('*.parquet')\n",
    ")\n",
    "full_df.limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>summary</th><th>passenger_count</th></tr>\n",
       "<tr><td>count</td><td>7667945</td></tr>\n",
       "<tr><td>mean</td><td>1.5670317144945614</td></tr>\n",
       "<tr><td>stddev</td><td>1.2244198591042095</td></tr>\n",
       "<tr><td>min</td><td>0.0</td></tr>\n",
       "<tr><td>max</td><td>9.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+------------------+\n",
       "|summary|   passenger_count|\n",
       "+-------+------------------+\n",
       "|  count|           7667945|\n",
       "|   mean|1.5670317144945614|\n",
       "| stddev|1.2244198591042095|\n",
       "|    min|               0.0|\n",
       "|    max|               9.0|\n",
       "+-------+------------------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/07/28 23:05:43 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 2115354 ms exceeds timeout 120000 ms\n",
      "23/07/28 23:05:43 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "sdf.select('passenger_count').describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
