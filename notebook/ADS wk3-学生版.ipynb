{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MAST30034 Applied Data Science week 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 1选题：\n",
    "- 不要过于刁钻\n",
    "- 不要过于简单\n",
    "- 想象力\n",
    "- 实际性\n",
    "\n",
    "eg：\n",
    "\n",
    "#### 预测类\n",
    "1. forecasting trip duration\n",
    "2. forecasting tip amount\n",
    "3. forecasting drop off location\n",
    "\n",
    "#### 分析类\n",
    "1. relation between weather and trip distance/fare/amount/tips\n",
    "2. relation between public events and trip amount\n",
    "3. relation between location and fare/tips/duration\n",
    "4. generalised analysis on fare/tips/duration\n",
    "\n",
    "#### 比较类\n",
    "1. impact of Covid-19 on taxis\n",
    "2. taxi demand in different public locations\n",
    "3. taxi demand throughout the day/a week/a year\n",
    "4. time series analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Topic: Generalized analysis on Tip amount**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Aim:\n",
    "    * Explore key factors on Tip amount\n",
    "    * Make predictions on it\n",
    "\n",
    "- Based on the perspective of taxi company and drivers\n",
    "\n",
    "- Choose of timeline and taxi type: 2019 and 2020, Yellow taxi\n",
    "\n",
    "- External Dataset: Weather\n",
    "\n",
    "- Assumptions:\n",
    "    * People have adapted living with Covid-19\n",
    "    * Only looking at those pay by credit card\n",
    "    * Weather is all the same throughout a whole day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 数据预处理\n",
    "\n",
    "我们可以把整个preliminary分为两个阶段：\n",
    "1. filter invalid data\n",
    "2. exclude outliers for analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from urllib.request import urlretrieve\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"ADS project 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.executor.memory\",\"2G\")\n",
    "    .config(\"spark.driver.memory\",\"4G\")\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.parquet.compression.codec\", \"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sbs\n",
    "import geopandas as gpd\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The timeline of year and month of data to use\n",
    "path_raw = f\"data/\"\n",
    "#path_curated = f\"../data/curated/tlc_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "sdf = spark.read.parquet(f'data/2019-01.parquet')\n",
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new features:\n",
    "- time duration\n",
    "- weekend or weekday\n",
    "- average speed\n",
    "- whether airport\n",
    "- tip rate\n",
    "- congestion zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean invalid data:\n",
    "- time duration < 60s\n",
    "- tip < 0\n",
    "- distance < 0\n",
    "- fare amount < 2.5\n",
    "- payment != 1\n",
    "- missing values\n",
    "- outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = add_feature(sdf)\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = clean_feature(sdf)\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. 画图\n",
    "\n",
    "- boxplot\n",
    "- scatterplot\n",
    "- histogram\n",
    "- pair plot\n",
    "- heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 0.1\n",
    "#SAMPLE_SIZE = 0.01\n",
    "cols = ['trip_distance', 'fare_amount', 'average_speed', 'time_duration', 'tip_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = sdf.sample(SAMPLE_SIZE, seed=1).toPandas()\n",
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quan_df():\n",
    "    colu = cols\n",
    "    inde = ['Q0', 'Q1', 'Q3', 'Q4', 'IQR']\n",
    "    return pd.DataFrame(index = inde, columns = colu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the quantiles for each feature, fill them into the quantile dataframe\n",
    "def find_quantile(df, quan_df):\n",
    "    # Find the quantiles for each feature in the cols\n",
    "    Q0 = df[cols].quantile(0.05)\n",
    "    Q1 = df[cols].quantile(0.25)\n",
    "    Q3 = df[cols].quantile(0.75)\n",
    "    Q4 = df[cols].quantile(0.95)\n",
    "    IQR = Q3 - Q1\n",
    "    # fill the quantiles into a dataframe\n",
    "    for fea in cols:    \n",
    "        quan_df.loc[\"Q0\", fea] = Q0[fea]\n",
    "        quan_df.loc[\"Q1\", fea] = Q1[fea]\n",
    "        quan_df.loc[\"Q3\", fea] = Q3[fea]\n",
    "        quan_df.loc[\"Q4\", fea] = Q4[fea]\n",
    "        quan_df.loc[\"IQR\", fea] = IQR[fea]\n",
    "    return quan_df, Q1, Q3, IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quan_df = create_quan_df()\n",
    "quan_df, Q1, Q3, IQR = find_quantile(sampled_df, quan_df)\n",
    "quan_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_df = sampled_df[~((sampled_df[cols] < (Q1 - 1.5*IQR)) | (sampled_df[cols] > (Q3 + 1.5*IQR))).any(axis=1)]\n",
    "box_plot(removed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画图也可以做Feature Analysis\n",
    "\n",
    "思路： 自己提出一些假设设想，逐步验证\n",
    "\n",
    "- Is tip amount itself a feature following certain distribution?\n",
    "- Which of the numeric features are closest related to the final tip amount?\n",
    "- Which of the chosen categorical features are closest related to the final tip amount?\n",
    "- Are the Tip habit in 2019 and 2021 performing to be largely different?\n",
    "- How are the tipping habit different with respect to the Pick Up & Drop Off Location?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_plot(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbs.set_theme(style = 'darkgrid')\n",
    "sbs.histplot(sampled_df['tip_amount'], kde = True)\n",
    "plt.title('Tip Amount in 2019', size = 15)\n",
    "plt.xlabel('Tip Amount', size = 13)\n",
    "plt.savefig(\"plots/Tip Amount\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Merge External Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_cols = ['Month,Date', 'Temperature (F)', 'Wind Speed (mph)', 'is_rainy']\n",
    "external = spark.read.csv(f'data/NYC weather 2019 cleaned.csv', header = True)\n",
    "# take the needed columns only\n",
    "external = external.select(external_cols)\n",
    "# merge the two datasets\n",
    "merged = sdf.join(external, on = 'Month,Date', how = 'leftouter')\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Geospatial Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the average Tip amount in different PickUp and DropOff Locations in 2021\n",
    "gdf, geoJSON = create_geo()\n",
    "df_pu = create_proportion(sdf, 'PU', gdf)\n",
    "m_pu = plot_map(df_pu, geoJSON, 'PU')\n",
    "df_do = create_proportion(sdf, 'DO', gdf)\n",
    "m_do = plot_map(df_do, geoJSON, 'DO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Analysis on Categorical feature and Continuous feature\n",
    "\n",
    "- For Continuous features, use heatmap\n",
    "\n",
    "- For Categorical feautres, use aggregate and ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_results = sdf \\\n",
    "                    .groupBy(cols) \\\n",
    "                    .agg(\n",
    "                        # take the mean of each with respect to the combinations of categorical features\n",
    "                        F.mean(\"tip_amount\").alias(\"avg_tip_amount\"),\n",
    "                        F.mean(\"tip_rate\").alias(\"avg_tip_rate\")\n",
    "                    ).orderBy('avg_tip_amount')\n",
    "                    # order by Avg Tip Amount in ascending order\n",
    "                    \n",
    "\n",
    "aggregated_results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. 统计模型\n",
    "线性模型的四个假设\n",
    "- 线性关系：自变量x和因变量y之间存在线性关系\n",
    "- 独立：残差是独立的，不受其他因素影响（E.g 残差不应随着时间增长而增长）\n",
    "- 同方差：对于每个x，残差都应是恒定的\n",
    "- 正态分布：残差应符合正态分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其他可以考虑使用的models：\n",
    "\n",
    "Classification：\n",
    "- LR\n",
    "- SVM\n",
    "- BNB\n",
    "- RF\n",
    "\n",
    "Regression：\n",
    "- GLM\n",
    "- RFR\n",
    "- XGB\n",
    "- MLP\n",
    "\n",
    "Evaluation Metrics：\n",
    "- MSE\n",
    "- MAE\n",
    "- RMSE\n",
    "- Pearson Correlation\n",
    "- Acc, Recall, Precision, F1\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate using plots:\n",
    "- Distribution of residuals\n",
    "- QQ plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sp.stats.probplot(plot['residual'], plot=ax, fit=True)\n",
    "# save the figure\n",
    "plt.savefig('../plots/QQ plot')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
